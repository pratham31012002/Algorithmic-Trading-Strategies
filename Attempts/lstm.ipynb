{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1786,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_size = 0.2\n",
    "\n",
    "tickers_to_use = ['AAPL.O', 'MSFT.O', 'INTC.O', 'AMZN.O', 'GS.N']\n",
    "# tickers_to_use = ['AAPL.O']\n",
    "n_tickers = len(tickers_to_use)\n",
    "\n",
    "use_returns = False\n",
    "discretize_returns = False\n",
    "discretize_rsi = False\n",
    "use_log_returns = False\n",
    "use_past_positions = False\n",
    "scaler = MinMaxScaler()\n",
    "classification = False\n",
    "num_classes = 2\n",
    "single_model_for_all_tickers = False\n",
    "margin_within = 0.007\n",
    "\n",
    "window_length = 5\n",
    "learning_rate = 0.00001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "dropout = 0.1\n",
    "early_stopping_patience = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1788,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL.O</th>\n",
       "      <th>MSFT.O</th>\n",
       "      <th>INTC.O</th>\n",
       "      <th>AMZN.O</th>\n",
       "      <th>GS.N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.572827</td>\n",
       "      <td>30.950</td>\n",
       "      <td>20.88</td>\n",
       "      <td>133.90</td>\n",
       "      <td>173.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.625684</td>\n",
       "      <td>30.960</td>\n",
       "      <td>20.87</td>\n",
       "      <td>134.69</td>\n",
       "      <td>176.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.138541</td>\n",
       "      <td>30.770</td>\n",
       "      <td>20.80</td>\n",
       "      <td>132.25</td>\n",
       "      <td>174.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.082827</td>\n",
       "      <td>30.452</td>\n",
       "      <td>20.60</td>\n",
       "      <td>130.00</td>\n",
       "      <td>177.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>30.282827</td>\n",
       "      <td>30.660</td>\n",
       "      <td>20.83</td>\n",
       "      <td>133.52</td>\n",
       "      <td>174.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25</th>\n",
       "      <td>182.170000</td>\n",
       "      <td>98.390</td>\n",
       "      <td>50.71</td>\n",
       "      <td>1663.15</td>\n",
       "      <td>221.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26</th>\n",
       "      <td>184.430000</td>\n",
       "      <td>99.080</td>\n",
       "      <td>49.67</td>\n",
       "      <td>1691.09</td>\n",
       "      <td>221.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-27</th>\n",
       "      <td>184.160000</td>\n",
       "      <td>97.540</td>\n",
       "      <td>48.76</td>\n",
       "      <td>1660.51</td>\n",
       "      <td>220.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>185.500000</td>\n",
       "      <td>98.630</td>\n",
       "      <td>49.25</td>\n",
       "      <td>1701.45</td>\n",
       "      <td>223.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>185.110000</td>\n",
       "      <td>98.610</td>\n",
       "      <td>49.71</td>\n",
       "      <td>1699.80</td>\n",
       "      <td>220.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2138 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL.O  MSFT.O  INTC.O   AMZN.O    GS.N\n",
       "Date                                                   \n",
       "2010-01-04   30.572827  30.950   20.88   133.90  173.08\n",
       "2010-01-05   30.625684  30.960   20.87   134.69  176.14\n",
       "2010-01-06   30.138541  30.770   20.80   132.25  174.26\n",
       "2010-01-07   30.082827  30.452   20.60   130.00  177.67\n",
       "2010-01-08   30.282827  30.660   20.83   133.52  174.31\n",
       "...                ...     ...     ...      ...     ...\n",
       "2018-06-25  182.170000  98.390   50.71  1663.15  221.54\n",
       "2018-06-26  184.430000  99.080   49.67  1691.09  221.58\n",
       "2018-06-27  184.160000  97.540   48.76  1660.51  220.18\n",
       "2018-06-28  185.500000  98.630   49.25  1701.45  223.42\n",
       "2018-06-29  185.110000  98.610   49.71  1699.80  220.57\n",
       "\n",
       "[2138 rows x 5 columns]"
      ]
     },
     "execution_count": 1788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('tr_eikon_eod_data.csv', index_col = 0, parse_dates = True)\n",
    "data = pd.DataFrame(raw[tickers_to_use].dropna())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL.O</th>\n",
       "      <th>MSFT.O</th>\n",
       "      <th>INTC.O</th>\n",
       "      <th>AMZN.O</th>\n",
       "      <th>GS.N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL.O</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924437</td>\n",
       "      <td>0.920085</td>\n",
       "      <td>0.888065</td>\n",
       "      <td>0.766361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT.O</th>\n",
       "      <td>0.924437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>0.976018</td>\n",
       "      <td>0.839008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTC.O</th>\n",
       "      <td>0.920085</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909608</td>\n",
       "      <td>0.762886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN.O</th>\n",
       "      <td>0.888065</td>\n",
       "      <td>0.976018</td>\n",
       "      <td>0.909608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS.N</th>\n",
       "      <td>0.766361</td>\n",
       "      <td>0.839008</td>\n",
       "      <td>0.762886</td>\n",
       "      <td>0.783544</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAPL.O    MSFT.O    INTC.O    AMZN.O      GS.N\n",
       "AAPL.O  1.000000  0.924437  0.920085  0.888065  0.766361\n",
       "MSFT.O  0.924437  1.000000  0.950978  0.976018  0.839008\n",
       "INTC.O  0.920085  0.950978  1.000000  0.909608  0.762886\n",
       "AMZN.O  0.888065  0.976018  0.909608  1.000000  0.783544\n",
       "GS.N    0.766361  0.839008  0.762886  0.783544  1.000000"
      ]
     },
     "execution_count": 1789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of the tickers:\n",
      "AAPL.O     40.551559\n",
      "MSFT.O     19.527712\n",
      "INTC.O      8.172160\n",
      "AMZN.O    372.307818\n",
      "GS.N       42.483935\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Standard deviation of the data\n",
    "print(\"Standard deviation of the tickers:\")\n",
    "print(data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL.O     28.130857\n",
      "MSFT.O     10.143635\n",
      "INTC.O      5.268343\n",
      "AMZN.O    175.758492\n",
      "GS.N       28.997224\n",
      "dtype: float64\n",
      "AAPL.O     22.727231\n",
      "MSFT.O     12.969566\n",
      "INTC.O      6.935527\n",
      "AMZN.O    290.692329\n",
      "GS.N       18.793846\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the standard deviation of the prices in train and test sets\n",
    "test_size = 0.2\n",
    "print(data[:int(len(data) * (1 - test_size))].std())\n",
    "# Print the standard deviation of the prices in test set\n",
    "print(data[int(len(data) * (1 - test_size)):].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: xlabel='Date'>, <Axes: xlabel='Date'>,\n",
       "       <Axes: xlabel='Date'>, <Axes: xlabel='Date'>,\n",
       "       <Axes: xlabel='Date'>], dtype=object)"
      ]
     },
     "execution_count": 1790,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(subplots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for AAPL\n",
    "# # Get first date point\n",
    "# start_date = data.index.min()\n",
    "# # Get last date point\n",
    "# end_date = data.index.max() + pd.Timedelta(days = 1)\n",
    "# # Get stock data\n",
    "# stock_data = yf.download('AAPL', start = start_date, end = end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1792,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Join data and stock_data on date\n",
    "# data = data.join(stock_data)\n",
    "# data.drop('Adj Close', axis = 1, inplace = True)\n",
    "# data.drop('Close', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add moving average of previous 40 business days and previous 150 business days as features\n",
    "# for col in data.columns:\n",
    "#     sma_short = data[col].shift(1).rolling(window = 40).mean()\n",
    "#     sma_long = data[col].shift(1).rolling(window = 150).mean()\n",
    "#     data[col + '_sma'] = np.where(sma_short > sma_long, 1, -1) # Another approach is to have both sma_short and sma_long as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1794,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RSI as a feature\n",
    "# def rsi(series, period):\n",
    "#     delta = series.diff()\n",
    "#     gain = (delta.where(delta > 0, 0)).rolling(window = period).mean()\n",
    "#     loss = (-delta.where(delta < 0, 0)).rolling(window = period).mean()\n",
    "#     rs = gain / loss\n",
    "#     return 100 - (100 / (1 + rs))\n",
    "# for col in data[tickers_to_use]:\n",
    "#     data[col + '_RSI'] = rsi(data[col], 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1795,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(data, window=10):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_ema(data, window=12):\n",
    "    return data.ewm(span=window, adjust=False).mean()\n",
    "\n",
    "def calculate_macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "    short_ema = calculate_ema(data, short_window)\n",
    "    long_ema = calculate_ema(data, long_window)\n",
    "    macd_line = short_ema - long_ema\n",
    "    signal_line = calculate_ema(macd_line, signal_window)\n",
    "    histogram = macd_line - signal_line\n",
    "    return macd_line, signal_line, histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1796,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi_trading_strategy(rsi_data, low=30, high=70):\n",
    "    buy_signal = (rsi_data.shift(1) < low) & (rsi_data > low)\n",
    "    sell_signal = (rsi_data.shift(1) > high) & (rsi_data < high)\n",
    "    return buy_signal.astype(int) - sell_signal.astype(int)\n",
    "\n",
    "def macd_trading_strategy(macd_line, signal_line):\n",
    "    buy_signal = macd_line.shift(1) < signal_line.shift(1)\n",
    "    sell_signal = macd_line.shift(1) > signal_line.shift(1)\n",
    "    return buy_signal.astype(int) - sell_signal.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1797,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL.O</th>\n",
       "      <th>MSFT.O</th>\n",
       "      <th>INTC.O</th>\n",
       "      <th>AMZN.O</th>\n",
       "      <th>GS.N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.572827</td>\n",
       "      <td>30.950</td>\n",
       "      <td>20.88</td>\n",
       "      <td>133.90</td>\n",
       "      <td>173.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.625684</td>\n",
       "      <td>30.960</td>\n",
       "      <td>20.87</td>\n",
       "      <td>134.69</td>\n",
       "      <td>176.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.138541</td>\n",
       "      <td>30.770</td>\n",
       "      <td>20.80</td>\n",
       "      <td>132.25</td>\n",
       "      <td>174.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.082827</td>\n",
       "      <td>30.452</td>\n",
       "      <td>20.60</td>\n",
       "      <td>130.00</td>\n",
       "      <td>177.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>30.282827</td>\n",
       "      <td>30.660</td>\n",
       "      <td>20.83</td>\n",
       "      <td>133.52</td>\n",
       "      <td>174.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25</th>\n",
       "      <td>182.170000</td>\n",
       "      <td>98.390</td>\n",
       "      <td>50.71</td>\n",
       "      <td>1663.15</td>\n",
       "      <td>221.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26</th>\n",
       "      <td>184.430000</td>\n",
       "      <td>99.080</td>\n",
       "      <td>49.67</td>\n",
       "      <td>1691.09</td>\n",
       "      <td>221.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-27</th>\n",
       "      <td>184.160000</td>\n",
       "      <td>97.540</td>\n",
       "      <td>48.76</td>\n",
       "      <td>1660.51</td>\n",
       "      <td>220.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>185.500000</td>\n",
       "      <td>98.630</td>\n",
       "      <td>49.25</td>\n",
       "      <td>1701.45</td>\n",
       "      <td>223.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>185.110000</td>\n",
       "      <td>98.610</td>\n",
       "      <td>49.71</td>\n",
       "      <td>1699.80</td>\n",
       "      <td>220.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2138 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL.O  MSFT.O  INTC.O   AMZN.O    GS.N\n",
       "Date                                                   \n",
       "2010-01-04   30.572827  30.950   20.88   133.90  173.08\n",
       "2010-01-05   30.625684  30.960   20.87   134.69  176.14\n",
       "2010-01-06   30.138541  30.770   20.80   132.25  174.26\n",
       "2010-01-07   30.082827  30.452   20.60   130.00  177.67\n",
       "2010-01-08   30.282827  30.660   20.83   133.52  174.31\n",
       "...                ...     ...     ...      ...     ...\n",
       "2018-06-25  182.170000  98.390   50.71  1663.15  221.54\n",
       "2018-06-26  184.430000  99.080   49.67  1691.09  221.58\n",
       "2018-06-27  184.160000  97.540   48.76  1660.51  220.18\n",
       "2018-06-28  185.500000  98.630   49.25  1701.45  223.42\n",
       "2018-06-29  185.110000  98.610   49.71  1699.80  220.57\n",
       "\n",
       "[2138 rows x 5 columns]"
      ]
     },
     "execution_count": 1798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1799,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, features, target_feature_indices, rsi_index = None):\n",
    "    ticker_data = data[features].values\n",
    "\n",
    "    if use_returns:\n",
    "        returns = ticker_data[1:, target_feature_indices] / ticker_data[:-1, target_feature_indices] - 1\n",
    "        remaining_features = np.delete(ticker_data, target_feature_indices, axis = 1)[1:, :]\n",
    "        features = np.column_stack((returns, remaining_features))\n",
    "    elif use_log_returns:\n",
    "        returns = np.log(ticker_data[1:, target_feature_indices] / ticker_data[:-1, target_feature_indices])\n",
    "        remaining_features = np.delete(ticker_data, target_feature_indices, axis = 1)[1:, :]\n",
    "        features = np.column_stack((returns, remaining_features))\n",
    "\n",
    "    if (use_returns or use_log_returns) and discretize_returns:\n",
    "        bins = defaultdict(list)\n",
    "        for i in range(len(target_feature_indices)):\n",
    "            bins[i] = [np.mean(returns[:, i]) - 2 * np.std(returns[:, i]), np.mean(returns[:, i]) - np.std(returns[:, i]), np.mean(returns[:, i]), np.mean(returns[:, i]) + np.std(returns[:, i]), np.mean(returns[:, i]) + 2 * np.std(returns[:, i])]\n",
    "        for i in range(len(returns)):\n",
    "            for j in range(len(target_feature_indices)):\n",
    "                features[i, j] = np.digitize(returns[i, j], bins[j])\n",
    "    elif use_past_positions:\n",
    "        features = np.zeros((len(ticker_data) - 1, len(ticker)))\n",
    "        for i in range(1, len(ticker_data)):\n",
    "            for j in range(len(target_feature_indices)):\n",
    "                features[i - 1, j] = np.where(ticker_data[i, j] > ticker_data[i - 1, j], 1, 0)\n",
    "        remaining_features = np.delete(ticker_data, target_feature_indices, axis = 1)[1:, :]\n",
    "        features = np.column_stack((features, remaining_features))\n",
    "    else:\n",
    "        features = ticker_data\n",
    "\n",
    "    if rsi_index is not None and discretize_rsi:\n",
    "        # discretize features[rsi_index]\n",
    "        bins = [0, 30, 70, 100]\n",
    "        features[:, rsi_index] = np.digitize(features[:, rsi_index], bins)\n",
    "    \n",
    "    features_scaled = features\n",
    "    if scaler:\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    X, Y = [], []\n",
    "    for i in range(len(features_scaled) - window_length):\n",
    "        X.append(features_scaled[i:i + window_length])\n",
    "        if classification:\n",
    "            if use_returns or use_log_returns:\n",
    "                Y.append(np.where(returns[i + window_length, target_feature_indices] > 0, 1, 0))\n",
    "            elif use_past_positions:\n",
    "                Y.append(features[i + window_length, target_feature_indices])\n",
    "            else:\n",
    "                Y.append(np.where(ticker_data[i + window_length, target_feature_indices] > ticker_data[i + window_length - 1, target_feature_indices], 1, 0))\n",
    "        else:\n",
    "            if use_returns or use_log_returns:\n",
    "                Y.append(returns[i + window_length, target_feature_indices])\n",
    "            else:\n",
    "                Y.append(features_scaled[i + window_length, target_feature_indices])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1800,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    input_layer = Input(shape = input_shape)\n",
    "    shared_lstm = LSTM(100, activation = 'relu', return_sequences = True)(input_layer)\n",
    "    shared_lstm = Dropout(dropout)(shared_lstm)\n",
    "    shared_lstm = LSTM(100, activation = 'relu', return_sequences = True)(shared_lstm)\n",
    "    shared_lstm = Dropout(dropout)(shared_lstm)\n",
    "    # shared_lstm = LSTM(200, activation = 'relu', return_sequences = True)(shared_lstm)\n",
    "    # shared_lstm = Dropout(dropout)(shared_lstm)\n",
    "    shared_lstm = LSTM(50, activation = 'relu', return_sequences = False)(shared_lstm)\n",
    "    # shared_lstm = Dropout(dropout)(shared_lstm)\n",
    "    if single_model_for_all_tickers:\n",
    "        n_features_to_predict = len(tickers_to_use)\n",
    "    else:\n",
    "        n_features_to_predict = 1\n",
    "    if classification:\n",
    "        outputs = []\n",
    "        for i in range(n_features_to_predict):\n",
    "            output = Dense(num_classes, activation = 'softmax', name = 'output_' + str(i + 1))(shared_lstm)\n",
    "            outputs.append(output)\n",
    "        model = Model(inputs = input_layer, outputs = outputs)\n",
    "        model.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'categorical_crossentropy', metrics = ['accuracy'] * n_features_to_predict)\n",
    "    else:\n",
    "        output = Dense(n_features_to_predict, activation = 'linear')(shared_lstm)\n",
    "        model = Model(inputs = input_layer, outputs = output)\n",
    "        model.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01549136]\n",
      " [0.01344128]\n",
      " [0.01595455]\n",
      " [0.01490807]\n",
      " [0.01190587]\n",
      " [0.01972017]\n",
      " [0.01687666]\n",
      " [0.01374322]\n",
      " [0.0048893 ]\n",
      " [0.00945693]]\n",
      "Epoch 1/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1189 - val_loss: 0.5975\n",
      "Epoch 2/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1187 - val_loss: 0.5873\n",
      "Epoch 3/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1151 - val_loss: 0.5762\n",
      "Epoch 4/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1118 - val_loss: 0.5636\n",
      "Epoch 5/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1100 - val_loss: 0.5487\n",
      "Epoch 6/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.1055 - val_loss: 0.5329\n",
      "Epoch 7/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0972 - val_loss: 0.5157\n",
      "Epoch 8/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0957 - val_loss: 0.4970\n",
      "Epoch 9/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0853 - val_loss: 0.4762\n",
      "Epoch 10/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0796 - val_loss: 0.4531\n",
      "Epoch 11/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0759 - val_loss: 0.4272\n",
      "Epoch 12/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0712 - val_loss: 0.3991\n",
      "Epoch 13/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0628 - val_loss: 0.3680\n",
      "Epoch 14/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0579 - val_loss: 0.3344\n",
      "Epoch 15/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0488 - val_loss: 0.2988\n",
      "Epoch 16/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0427 - val_loss: 0.2612\n",
      "Epoch 17/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0337 - val_loss: 0.2232\n",
      "Epoch 18/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0280 - val_loss: 0.1853\n",
      "Epoch 19/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0208 - val_loss: 0.1500\n",
      "Epoch 20/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0166 - val_loss: 0.1174\n",
      "Epoch 21/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0131 - val_loss: 0.0908\n",
      "Epoch 22/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0099 - val_loss: 0.0706\n",
      "Epoch 23/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0092 - val_loss: 0.0549\n",
      "Epoch 24/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.0448\n",
      "Epoch 25/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0073 - val_loss: 0.0368\n",
      "Epoch 26/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0067 - val_loss: 0.0310\n",
      "Epoch 27/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0059 - val_loss: 0.0260\n",
      "Epoch 28/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0218\n",
      "Epoch 29/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0180\n",
      "Epoch 30/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0042 - val_loss: 0.0148\n",
      "Epoch 31/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0118\n",
      "Epoch 32/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - val_loss: 0.0096\n",
      "Epoch 33/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0029 - val_loss: 0.0070\n",
      "Epoch 34/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 35/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 36/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 38/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 39/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0013 - val_loss: 9.7681e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 8.6818e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8071e-04 - val_loss: 8.5529e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.8785e-04 - val_loss: 9.3121e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.4397e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.3380e-04 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.6620e-04 - val_loss: 0.0014\n",
      "Epoch 46/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.5558e-04 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 6.2985e-04 - val_loss: 0.0016\n",
      "Epoch 48/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.3724e-04 - val_loss: 0.0016\n",
      "Epoch 49/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 5.2932e-04 - val_loss: 0.0016\n",
      "Epoch 50/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.3008e-04 - val_loss: 0.0015\n",
      "Epoch 51/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.1465e-04 - val_loss: 0.0015\n",
      "Epoch 52/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 5.1718e-04 - val_loss: 0.0015\n",
      "Epoch 53/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.0628e-04 - val_loss: 0.0014\n",
      "Epoch 54/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.6864e-04 - val_loss: 0.0014\n",
      "Epoch 55/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.7991e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2128e-04 - val_loss: 0.0012\n",
      "Epoch 57/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6534e-04 - val_loss: 0.0011\n",
      "Epoch 58/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.2463e-04 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6924e-04 - val_loss: 0.0011\n",
      "Epoch 60/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.9406e-04 - val_loss: 0.0011\n",
      "Epoch 61/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.9852e-04 - val_loss: 0.0011\n",
      "Epoch 62/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2584e-04 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7601e-04 - val_loss: 0.0011\n",
      "Epoch 64/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.2442e-04 - val_loss: 0.0011\n",
      "Epoch 65/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.3224e-04 - val_loss: 9.7150e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9808e-04 - val_loss: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1251e-04 - val_loss: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.1413e-04 - val_loss: 9.4812e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2042e-04 - val_loss: 9.3321e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9684e-04 - val_loss: 8.8622e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1604e-04 - val_loss: 9.4899e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.8215e-04 - val_loss: 9.3748e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2498e-04 - val_loss: 8.9608e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.8491e-04 - val_loss: 8.8318e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.3372e-04 - val_loss: 8.8976e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.6361e-04 - val_loss: 8.7969e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 4.2836e-04 - val_loss: 8.7935e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.2027e-04 - val_loss: 9.0878e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.2287e-04 - val_loss: 9.5843e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.1300e-04 - val_loss: 8.8372e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.9346e-04 - val_loss: 8.9368e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0498e-04 - val_loss: 8.9351e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.3864e-04 - val_loss: 8.8093e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.0017e-04 - val_loss: 8.5039e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0637e-04 - val_loss: 8.7145e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.7678e-04 - val_loss: 8.7690e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.3113e-04 - val_loss: 8.7049e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.6616e-04 - val_loss: 8.7348e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0459e-04 - val_loss: 8.8089e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.9603e-04 - val_loss: 8.7282e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.7648e-04 - val_loss: 8.8842e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1504e-04 - val_loss: 8.9626e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.7345e-04 - val_loss: 8.7866e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.1399e-04 - val_loss: 8.6053e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1051e-04 - val_loss: 8.5912e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.5348e-04 - val_loss: 8.5063e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 3.7205e-04 - val_loss: 8.3961e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.8496e-04 - val_loss: 8.4687e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0481e-04 - val_loss: 8.6750e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.6939e-04 - val_loss: 8.6105e-04\n",
      "[[0.09134373]\n",
      " [0.08882738]\n",
      " [0.09235028]\n",
      " [0.10002516]\n",
      " [0.09876699]\n",
      " [0.10178661]\n",
      " [0.095307  ]\n",
      " [0.08807247]\n",
      " [0.0748616 ]\n",
      " [0.07939104]]\n",
      "Epoch 1/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.0457 - val_loss: 0.5067\n",
      "Epoch 2/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0447 - val_loss: 0.5006\n",
      "Epoch 3/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0435 - val_loss: 0.4945\n",
      "Epoch 4/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0410 - val_loss: 0.4881\n",
      "Epoch 5/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0425 - val_loss: 0.4812\n",
      "Epoch 6/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0399 - val_loss: 0.4736\n",
      "Epoch 7/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0367 - val_loss: 0.4649\n",
      "Epoch 8/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0351 - val_loss: 0.4546\n",
      "Epoch 9/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0358 - val_loss: 0.4427\n",
      "Epoch 10/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0339 - val_loss: 0.4285\n",
      "Epoch 11/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0297 - val_loss: 0.4126\n",
      "Epoch 12/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0277 - val_loss: 0.3952\n",
      "Epoch 13/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0252 - val_loss: 0.3758\n",
      "Epoch 14/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0234 - val_loss: 0.3545\n",
      "Epoch 15/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0208 - val_loss: 0.3312\n",
      "Epoch 16/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0186 - val_loss: 0.3064\n",
      "Epoch 17/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174 - val_loss: 0.2803\n",
      "Epoch 18/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0147 - val_loss: 0.2535\n",
      "Epoch 19/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0126 - val_loss: 0.2266\n",
      "Epoch 20/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0114 - val_loss: 0.2006\n",
      "Epoch 21/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0099 - val_loss: 0.1777\n",
      "Epoch 22/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0090 - val_loss: 0.1568\n",
      "Epoch 23/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0085 - val_loss: 0.1385\n",
      "Epoch 24/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.1229\n",
      "Epoch 25/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0067 - val_loss: 0.1066\n",
      "Epoch 26/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0938\n",
      "Epoch 27/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0803\n",
      "Epoch 28/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0044 - val_loss: 0.0683\n",
      "Epoch 29/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0039 - val_loss: 0.0560\n",
      "Epoch 30/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - val_loss: 0.0445\n",
      "Epoch 31/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0028 - val_loss: 0.0349\n",
      "Epoch 32/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0257\n",
      "Epoch 33/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0189\n",
      "Epoch 34/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0014 - val_loss: 0.0130\n",
      "Epoch 35/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0086\n",
      "Epoch 36/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1094e-04 - val_loss: 0.0053\n",
      "Epoch 37/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.7581e-04 - val_loss: 0.0033\n",
      "Epoch 38/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.6984e-04 - val_loss: 0.0019\n",
      "Epoch 39/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.3778e-04 - val_loss: 0.0014\n",
      "Epoch 40/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.9477e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3657e-04 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2955e-04 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.6382e-04 - val_loss: 0.0013\n",
      "Epoch 44/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.6452e-04 - val_loss: 0.0014\n",
      "Epoch 45/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.5797e-04 - val_loss: 0.0013\n",
      "Epoch 46/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 2.7100e-04 - val_loss: 0.0013\n",
      "Epoch 47/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.7799e-04 - val_loss: 0.0014\n",
      "Epoch 48/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.7252e-04 - val_loss: 0.0013\n",
      "Epoch 49/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.5724e-04 - val_loss: 0.0013\n",
      "Epoch 50/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.5222e-04 - val_loss: 0.0013\n",
      "Epoch 51/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 2.7916e-04 - val_loss: 0.0012\n",
      "Epoch 52/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.3934e-04 - val_loss: 0.0012\n",
      "Epoch 53/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7663e-04 - val_loss: 0.0012\n",
      "Epoch 54/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.5759e-04 - val_loss: 0.0012\n",
      "Epoch 55/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5307e-04 - val_loss: 0.0012\n",
      "Epoch 56/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.7149e-04 - val_loss: 0.0012\n",
      "Epoch 57/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.7584e-04 - val_loss: 0.0012\n",
      "Epoch 58/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.4561e-04 - val_loss: 0.0012\n",
      "Epoch 59/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.4585e-04 - val_loss: 0.0012\n",
      "Epoch 60/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.3539e-04 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.6768e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.4984e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.3171e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.4895e-04 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.3035e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.2923e-04 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.2563e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.4310e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.5442e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1644e-04 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.5049e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.4991e-04 - val_loss: 0.0012\n",
      "Epoch 73/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.4183e-04 - val_loss: 0.0012\n",
      "Epoch 74/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 2.4109e-04 - val_loss: 0.0012\n",
      "Epoch 75/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.2895e-04 - val_loss: 0.0012\n",
      "Epoch 76/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.4632e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.6412e-04 - val_loss: 0.0012\n",
      "Epoch 78/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.2588e-04 - val_loss: 0.0012\n",
      "Epoch 79/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.0251e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.2777e-04 - val_loss: 0.0012\n",
      "Epoch 81/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.5368e-04 - val_loss: 0.0012\n",
      "Epoch 82/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.4516e-04 - val_loss: 0.0012\n",
      "Epoch 83/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.2034e-04 - val_loss: 0.0012\n",
      "Epoch 84/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.4924e-04 - val_loss: 0.0012\n",
      "Epoch 85/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.2179e-04 - val_loss: 0.0012\n",
      "Epoch 86/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 2.3766e-04 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.1217e-04 - val_loss: 0.0012\n",
      "Epoch 88/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.4878e-04 - val_loss: 0.0012\n",
      "Epoch 89/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.3990e-04 - val_loss: 0.0011\n",
      "Epoch 90/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.1449e-04 - val_loss: 0.0011\n",
      "Epoch 91/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 2.1172e-04 - val_loss: 0.0011\n",
      "Epoch 92/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.2913e-04 - val_loss: 0.0011\n",
      "Epoch 93/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0736e-04 - val_loss: 0.0012\n",
      "Epoch 94/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.1859e-04 - val_loss: 0.0012\n",
      "Epoch 95/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.2313e-04 - val_loss: 0.0012\n",
      "Epoch 96/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.2043e-04 - val_loss: 0.0012\n",
      "Epoch 97/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.3377e-04 - val_loss: 0.0012\n",
      "Epoch 98/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.3435e-04 - val_loss: 0.0011\n",
      "Epoch 99/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.1848e-04 - val_loss: 0.0012\n",
      "Epoch 100/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.3626e-04 - val_loss: 0.0012\n",
      "[[0.0833439 ]\n",
      " [0.074667  ]\n",
      " [0.08359762]\n",
      " [0.09679056]\n",
      " [0.07953825]\n",
      " [0.08588101]\n",
      " [0.08664214]\n",
      " [0.08055309]\n",
      " [0.05695801]\n",
      " [0.06736014]]\n",
      "Epoch 1/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0680 - val_loss: 0.3982\n",
      "Epoch 2/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0645 - val_loss: 0.3920\n",
      "Epoch 3/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0611 - val_loss: 0.3849\n",
      "Epoch 4/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0613 - val_loss: 0.3773\n",
      "Epoch 5/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0583 - val_loss: 0.3691\n",
      "Epoch 6/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0569 - val_loss: 0.3599\n",
      "Epoch 7/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0550 - val_loss: 0.3498\n",
      "Epoch 8/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0518 - val_loss: 0.3387\n",
      "Epoch 9/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0484 - val_loss: 0.3264\n",
      "Epoch 10/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0451 - val_loss: 0.3127\n",
      "Epoch 11/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0415 - val_loss: 0.2976\n",
      "Epoch 12/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0366 - val_loss: 0.2809\n",
      "Epoch 13/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0361 - val_loss: 0.2623\n",
      "Epoch 14/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0308 - val_loss: 0.2429\n",
      "Epoch 15/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0268 - val_loss: 0.2221\n",
      "Epoch 16/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0236 - val_loss: 0.2006\n",
      "Epoch 17/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0202 - val_loss: 0.1783\n",
      "Epoch 18/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0169 - val_loss: 0.1571\n",
      "Epoch 19/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0139 - val_loss: 0.1372\n",
      "Epoch 20/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0126 - val_loss: 0.1191\n",
      "Epoch 21/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0112 - val_loss: 0.1031\n",
      "Epoch 22/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0095 - val_loss: 0.0902\n",
      "Epoch 23/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0091 - val_loss: 0.0796\n",
      "Epoch 24/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0083 - val_loss: 0.0706\n",
      "Epoch 25/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0072 - val_loss: 0.0629\n",
      "Epoch 26/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0560\n",
      "Epoch 27/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0061 - val_loss: 0.0497\n",
      "Epoch 28/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0055 - val_loss: 0.0439\n",
      "Epoch 29/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0386\n",
      "Epoch 30/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - val_loss: 0.0330\n",
      "Epoch 31/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0038 - val_loss: 0.0277\n",
      "Epoch 32/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0232\n",
      "Epoch 33/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0188\n",
      "Epoch 34/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0148\n",
      "Epoch 35/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0020 - val_loss: 0.0117\n",
      "Epoch 36/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 37/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 38/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 39/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.5308e-04 - val_loss: 0.0032\n",
      "Epoch 40/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.6271e-04 - val_loss: 0.0023\n",
      "Epoch 41/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.7474e-04 - val_loss: 0.0017\n",
      "Epoch 42/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.3563e-04 - val_loss: 0.0014\n",
      "Epoch 43/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4548e-04 - val_loss: 0.0013\n",
      "Epoch 44/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.4716e-04 - val_loss: 0.0013\n",
      "Epoch 45/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.7478e-04 - val_loss: 0.0013\n",
      "Epoch 46/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.9931e-04 - val_loss: 0.0013\n",
      "Epoch 47/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.8595e-04 - val_loss: 0.0013\n",
      "Epoch 48/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 4.3135e-04 - val_loss: 0.0013\n",
      "Epoch 49/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 4.5119e-04 - val_loss: 0.0013\n",
      "Epoch 50/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.4827e-04 - val_loss: 0.0013\n",
      "Epoch 51/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.4404e-04 - val_loss: 0.0013\n",
      "Epoch 52/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2818e-04 - val_loss: 0.0013\n",
      "Epoch 53/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.5511e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.5107e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6281e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.3517e-04 - val_loss: 0.0013\n",
      "Epoch 57/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.1650e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.4595e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1920e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.7532e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.4461e-04 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5064e-04 - val_loss: 0.0013\n",
      "Epoch 63/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.4721e-04 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2662e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5401e-04 - val_loss: 0.0013\n",
      "Epoch 66/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.5982e-04 - val_loss: 0.0014\n",
      "Epoch 67/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.7709e-04 - val_loss: 0.0013\n",
      "Epoch 68/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2878e-04 - val_loss: 0.0014\n",
      "Epoch 69/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.5743e-04 - val_loss: 0.0013\n",
      "Epoch 70/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.4661e-04 - val_loss: 0.0014\n",
      "Epoch 71/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1335e-04 - val_loss: 0.0014\n",
      "Epoch 72/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 4.2750e-04 - val_loss: 0.0014\n",
      "Epoch 73/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.2040e-04 - val_loss: 0.0013\n",
      "Epoch 74/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1074e-04 - val_loss: 0.0014\n",
      "Epoch 75/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.2170e-04 - val_loss: 0.0014\n",
      "Epoch 76/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.5104e-04 - val_loss: 0.0013\n",
      "Epoch 77/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.4784e-04 - val_loss: 0.0013\n",
      "Epoch 78/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0731e-04 - val_loss: 0.0014\n",
      "Epoch 79/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.5254e-04 - val_loss: 0.0013\n",
      "Epoch 80/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 4.1119e-04 - val_loss: 0.0013\n",
      "Epoch 81/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.2037e-04 - val_loss: 0.0013\n",
      "Epoch 82/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.1726e-04 - val_loss: 0.0013\n",
      "Epoch 83/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.9572e-04 - val_loss: 0.0013\n",
      "Epoch 84/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0286e-04 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 4.1265e-04 - val_loss: 0.0013\n",
      "Epoch 86/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.3824e-04 - val_loss: 0.0014\n",
      "Epoch 87/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0172e-04 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.2420e-04 - val_loss: 0.0014\n",
      "Epoch 89/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.0106e-04 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.7010e-04 - val_loss: 0.0014\n",
      "Epoch 91/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.1602e-04 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.7607e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0183e-04 - val_loss: 0.0013\n",
      "Epoch 94/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.6002e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0650e-04 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.3764e-04 - val_loss: 0.0013\n",
      "Epoch 97/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5175e-04 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.6570e-04 - val_loss: 0.0013\n",
      "Epoch 99/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5804e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5622e-04 - val_loss: 0.0013\n",
      "[[0.01321864]\n",
      " [0.0114166 ]\n",
      " [0.01248881]\n",
      " [0.0114166 ]\n",
      " [0.01128866]\n",
      " [0.01157499]\n",
      " [0.01046014]\n",
      " [0.01097187]\n",
      " [0.00781007]\n",
      " [0.00712776]]\n",
      "Epoch 1/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0294 - val_loss: 0.4236\n",
      "Epoch 2/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0296 - val_loss: 0.4185\n",
      "Epoch 3/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0274 - val_loss: 0.4131\n",
      "Epoch 4/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0266 - val_loss: 0.4073\n",
      "Epoch 5/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0265 - val_loss: 0.4011\n",
      "Epoch 6/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0248 - val_loss: 0.3944\n",
      "Epoch 7/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0235 - val_loss: 0.3870\n",
      "Epoch 8/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0225 - val_loss: 0.3791\n",
      "Epoch 9/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0218 - val_loss: 0.3703\n",
      "Epoch 10/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0201 - val_loss: 0.3608\n",
      "Epoch 11/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0185 - val_loss: 0.3505\n",
      "Epoch 12/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0179 - val_loss: 0.3395\n",
      "Epoch 13/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0173 - val_loss: 0.3277\n",
      "Epoch 14/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0157 - val_loss: 0.3149\n",
      "Epoch 15/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0149 - val_loss: 0.3016\n",
      "Epoch 16/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0133 - val_loss: 0.2876\n",
      "Epoch 17/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0120 - val_loss: 0.2734\n",
      "Epoch 18/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0109 - val_loss: 0.2580\n",
      "Epoch 19/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.2429\n",
      "Epoch 20/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0099 - val_loss: 0.2278\n",
      "Epoch 21/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0093 - val_loss: 0.2131\n",
      "Epoch 22/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0083 - val_loss: 0.1985\n",
      "Epoch 23/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0074 - val_loss: 0.1850\n",
      "Epoch 24/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0069 - val_loss: 0.1712\n",
      "Epoch 25/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.1595\n",
      "Epoch 26/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.1469\n",
      "Epoch 27/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0060 - val_loss: 0.1345\n",
      "Epoch 28/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.1226\n",
      "Epoch 29/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.1110\n",
      "Epoch 30/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0040 - val_loss: 0.0990\n",
      "Epoch 31/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0870\n",
      "Epoch 32/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0756\n",
      "Epoch 33/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0645\n",
      "Epoch 34/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0532\n",
      "Epoch 35/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0428\n",
      "Epoch 36/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0339\n",
      "Epoch 37/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0260\n",
      "Epoch 38/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.3798e-04 - val_loss: 0.0191\n",
      "Epoch 39/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.5794e-04 - val_loss: 0.0142\n",
      "Epoch 40/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2314e-04 - val_loss: 0.0102\n",
      "Epoch 41/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1944e-04 - val_loss: 0.0074\n",
      "Epoch 42/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.6188e-04 - val_loss: 0.0052\n",
      "Epoch 43/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.9438e-04 - val_loss: 0.0039\n",
      "Epoch 44/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.7630e-04 - val_loss: 0.0034\n",
      "Epoch 45/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5261e-04 - val_loss: 0.0026\n",
      "Epoch 46/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5373e-04 - val_loss: 0.0023\n",
      "Epoch 47/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.5255e-04 - val_loss: 0.0022\n",
      "Epoch 48/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3800e-04 - val_loss: 0.0020\n",
      "Epoch 49/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.4308e-04 - val_loss: 0.0020\n",
      "Epoch 50/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3405e-04 - val_loss: 0.0020\n",
      "Epoch 51/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2590e-04 - val_loss: 0.0020\n",
      "Epoch 52/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.2520e-04 - val_loss: 0.0020\n",
      "Epoch 53/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.3351e-04 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2893e-04 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.3532e-04 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.1991e-04 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.2995e-04 - val_loss: 0.0022\n",
      "Epoch 58/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2187e-04 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.1034e-04 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 1.1953e-04 - val_loss: 0.0021\n",
      "Epoch 61/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.2907e-04 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1612e-04 - val_loss: 0.0021\n",
      "Epoch 63/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.4268e-04 - val_loss: 0.0020\n",
      "Epoch 64/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2733e-04 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2930e-04 - val_loss: 0.0022\n",
      "Epoch 66/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3404e-04 - val_loss: 0.0022\n",
      "Epoch 67/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1711e-04 - val_loss: 0.0022\n",
      "Epoch 68/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.3041e-04 - val_loss: 0.0022\n",
      "Epoch 69/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 1.2108e-04 - val_loss: 0.0021\n",
      "Epoch 70/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.3140e-04 - val_loss: 0.0021\n",
      "Epoch 71/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1541e-04 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2383e-04 - val_loss: 0.0020\n",
      "Epoch 73/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.1764e-04 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2615e-04 - val_loss: 0.0020\n",
      "Epoch 75/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.3071e-04 - val_loss: 0.0020\n",
      "Epoch 76/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.2312e-04 - val_loss: 0.0022\n",
      "Epoch 77/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.1668e-04 - val_loss: 0.0022\n",
      "Epoch 78/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.3184e-04 - val_loss: 0.0017\n",
      "Epoch 79/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.1549e-04 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.2830e-04 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.1787e-04 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2269e-04 - val_loss: 0.0019\n",
      "Epoch 83/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1201e-04 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1037e-04 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 1.1664e-04 - val_loss: 0.0019\n",
      "Epoch 86/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2218e-04 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.2318e-04 - val_loss: 0.0018\n",
      "Epoch 88/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.3004e-04 - val_loss: 0.0018\n",
      "Epoch 89/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2586e-04 - val_loss: 0.0016\n",
      "Epoch 90/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2375e-04 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1447e-04 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.2326e-04 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0746e-04 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.2349e-04 - val_loss: 0.0014\n",
      "Epoch 95/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.3376e-04 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.1963e-04 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.2642e-04 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 1.1455e-04 - val_loss: 0.0015\n",
      "Epoch 99/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.0225e-04 - val_loss: 0.0014\n",
      "Epoch 100/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.2210e-04 - val_loss: 0.0015\n",
      "[[0.45163723]\n",
      " [0.43149505]\n",
      " [0.43822706]\n",
      " [0.43531883]\n",
      " [0.4174386 ]\n",
      " [0.42632486]\n",
      " [0.43133348]\n",
      " [0.39406506]\n",
      " [0.35771219]\n",
      " [0.36234382]]\n",
      "Epoch 1/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.1506 - val_loss: 0.6312\n",
      "Epoch 2/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1458 - val_loss: 0.6219\n",
      "Epoch 3/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1458 - val_loss: 0.6112\n",
      "Epoch 4/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1393 - val_loss: 0.5997\n",
      "Epoch 5/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1386 - val_loss: 0.5878\n",
      "Epoch 6/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1327 - val_loss: 0.5748\n",
      "Epoch 7/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1264 - val_loss: 0.5600\n",
      "Epoch 8/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1212 - val_loss: 0.5432\n",
      "Epoch 9/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.1195 - val_loss: 0.5239\n",
      "Epoch 10/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.1082 - val_loss: 0.5025\n",
      "Epoch 11/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1017 - val_loss: 0.4782\n",
      "Epoch 12/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0940 - val_loss: 0.4512\n",
      "Epoch 13/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0869 - val_loss: 0.4215\n",
      "Epoch 14/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0798 - val_loss: 0.3884\n",
      "Epoch 15/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0674 - val_loss: 0.3527\n",
      "Epoch 16/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0598 - val_loss: 0.3133\n",
      "Epoch 17/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0505 - val_loss: 0.2723\n",
      "Epoch 18/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0420 - val_loss: 0.2298\n",
      "Epoch 19/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0313 - val_loss: 0.1884\n",
      "Epoch 20/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0243 - val_loss: 0.1497\n",
      "Epoch 21/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0175 - val_loss: 0.1158\n",
      "Epoch 22/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0133 - val_loss: 0.0883\n",
      "Epoch 23/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0105 - val_loss: 0.0673\n",
      "Epoch 24/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0086 - val_loss: 0.0526\n",
      "Epoch 25/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0072 - val_loss: 0.0429\n",
      "Epoch 26/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0067 - val_loss: 0.0361\n",
      "Epoch 27/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0062 - val_loss: 0.0308\n",
      "Epoch 28/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0058 - val_loss: 0.0273\n",
      "Epoch 29/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0053 - val_loss: 0.0239\n",
      "Epoch 30/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0047 - val_loss: 0.0210\n",
      "Epoch 31/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0044 - val_loss: 0.0186\n",
      "Epoch 32/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0161\n",
      "Epoch 33/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0138\n",
      "Epoch 34/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0119\n",
      "Epoch 35/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0033 - val_loss: 0.0099\n",
      "Epoch 36/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0081\n",
      "Epoch 37/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Epoch 38/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 39/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 40/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 41/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 42/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 43/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 44/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 45/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 46/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 49/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.7118e-04 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 8.7582e-04 - val_loss: 0.0011\n",
      "Epoch 52/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.4566e-04 - val_loss: 0.0011\n",
      "Epoch 53/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 9.2910e-04 - val_loss: 0.0011\n",
      "Epoch 54/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.6478e-04 - val_loss: 0.0011\n",
      "Epoch 55/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.3423e-04 - val_loss: 0.0011\n",
      "Epoch 56/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.2602e-04 - val_loss: 0.0011\n",
      "Epoch 57/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.6824e-04 - val_loss: 0.0011\n",
      "Epoch 58/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.2418e-04 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.1398e-04 - val_loss: 0.0011\n",
      "Epoch 60/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.5806e-04 - val_loss: 0.0011\n",
      "Epoch 61/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.7730e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.5290e-04 - val_loss: 0.0011\n",
      "Epoch 63/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.5707e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.0002e-04 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.9297e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.0545e-04 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 8.1241e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 7.8543e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.6356e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.6354e-04 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 8.3112e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.4413e-04 - val_loss: 0.0013\n",
      "Epoch 73/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 7.7766e-04 - val_loss: 0.0013\n",
      "Epoch 74/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.4244e-04 - val_loss: 0.0012\n",
      "Epoch 75/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.3831e-04 - val_loss: 0.0013\n",
      "Epoch 76/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 7.4861e-04 - val_loss: 0.0013\n",
      "Epoch 77/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.0105e-04 - val_loss: 0.0013\n",
      "Epoch 78/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 7.6316e-04 - val_loss: 0.0013\n",
      "Epoch 79/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 7.6708e-04 - val_loss: 0.0013\n",
      "Epoch 80/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 7.8821e-04 - val_loss: 0.0013\n",
      "Epoch 81/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.1116e-04 - val_loss: 0.0012\n",
      "Epoch 82/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.8006e-04 - val_loss: 0.0013\n",
      "Epoch 83/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.6083e-04 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.6794e-04 - val_loss: 0.0013\n",
      "Epoch 85/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.5429e-04 - val_loss: 0.0013\n",
      "Epoch 86/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 7.5463e-04 - val_loss: 0.0013\n",
      "Epoch 87/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.2789e-04 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.7426e-04 - val_loss: 0.0014\n",
      "Epoch 89/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.3146e-04 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.5949e-04 - val_loss: 0.0014\n",
      "Epoch 91/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.1229e-04 - val_loss: 0.0014\n",
      "Epoch 92/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.5579e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.4038e-04 - val_loss: 0.0013\n",
      "Epoch 94/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.4733e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.0404e-04 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.2453e-04 - val_loss: 0.0012\n",
      "Epoch 97/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.7042e-04 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.1646e-04 - val_loss: 0.0013\n",
      "Epoch 99/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.3896e-04 - val_loss: 0.0014\n",
      "Epoch 100/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.0230e-04 - val_loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "if single_model_for_all_tickers:\n",
    "    X, Y = prepare_data(data, data.columns, list(range(n_tickers)))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_size, shuffle = False)\n",
    "    model = build_model((window_length, n_tickers))\n",
    "    if classification:\n",
    "        Y_train = to_categorical(Y_train)\n",
    "        Y_test = to_categorical(Y_test)\n",
    "        Y_train_dict = {}\n",
    "        Y_test_dict = {}\n",
    "        for i in range(n_tickers):\n",
    "            Y_train_dict['output_' + str(i + 1)] = Y_train[:,i,:]\n",
    "            Y_test_dict['output_' + str(i + 1)] = Y_test[:,i,:]\n",
    "        model.fit(X_train, Y_train_dict, epochs = num_epochs, batch_size = batch_size, validation_data = (X_test, Y_test_dict))\n",
    "    else:\n",
    "        model.fit(X_train, Y_train, epochs = num_epochs, batch_size = batch_size, validation_data = (X_test, Y_test))\n",
    "else:\n",
    "    models = {}\n",
    "    test_data = {}\n",
    "    for ticker in tickers_to_use:\n",
    "        features_used = [ticker]\n",
    "        X, Y = prepare_data(data, features_used, [0])\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_size, shuffle = False)\n",
    "        # Choose first column of Y as target\n",
    "        if Y_train.ndim == 2:\n",
    "            Y_train = Y_train[:,0].reshape(-1, 1)\n",
    "            Y_test = Y_test[:,0].reshape(-1, 1)\n",
    "        else:\n",
    "            Y_train = Y_train.reshape(-1, 1)\n",
    "            Y_test = Y_test.reshape(-1, 1)\n",
    "        print(Y_train[:10])\n",
    "        test_data[ticker] = (X_test, Y_test)\n",
    "        model = build_model((window_length, len(features_used)))\n",
    "        if classification:\n",
    "            Y_train = to_categorical(Y_train)\n",
    "            Y_test = to_categorical(Y_test)\n",
    "            Y_train_dict = {'output_1': Y_train}\n",
    "            Y_test_dict = {'output_1': Y_test}\n",
    "            print(Y_train.shape, X_train.shape, Y_test.shape, X_test.shape)\n",
    "            model.fit(X_train, Y_train_dict, epochs = num_epochs, batch_size = batch_size, validation_data = (X_test, Y_test_dict))\n",
    "        else:\n",
    "            early_stopping = EarlyStopping(monitor = 'val_loss', patience = early_stopping_patience, restore_best_weights = True)\n",
    "            model.fit(X_train, Y_train, epochs = num_epochs, batch_size = batch_size, validation_data = (X_test, Y_test))\n",
    "        models[ticker] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1802,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals(prices, true_price, pct_within=0.05):\n",
    "    signals = np.zeros(len(prices))\n",
    "    for i in range(1, len(prices)):\n",
    "        prev_price = true_price[i - 1]\n",
    "        current_price = prices[i]\n",
    "        upper_bound = prev_price * (1 + pct_within)\n",
    "        lower_bound = prev_price * (1 - pct_within)\n",
    "        \n",
    "        if current_price >= lower_bound and current_price <= upper_bound:\n",
    "            if signals[i - 1] == 0:\n",
    "                signals[i] = 1 if current_price > prev_price else -1\n",
    "            else:\n",
    "                signals[i] = signals[i - 1]\n",
    "        elif current_price > upper_bound:\n",
    "            signals[i] = 1  # Buy signal\n",
    "        elif current_price < lower_bound:\n",
    "            signals[i] = -1  # Sell signal\n",
    "    \n",
    "    return signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns without tweaking the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL.O 1.2116568745809286\n",
      "AAPL.O 0.5180332588638599\n",
      "AAPL.O 1.580515710382514\n",
      "MSFT.O 1.067668451980722\n",
      "MSFT.O 0.9219891431548601\n",
      "MSFT.O 1.7140622284025726\n",
      "INTC.O 1.8223659503291019\n",
      "INTC.O 0.6787224405057993\n",
      "INTC.O 1.3998873556744589\n",
      "AMZN.O 1.0612666484890965\n",
      "AMZN.O 0.6280228806160426\n",
      "AMZN.O 2.078782912839833\n",
      "GS.N 0.8378191684226795\n",
      "GS.N 0.9407119317626614\n",
      "GS.N 1.2639390292819888\n"
     ]
    }
   ],
   "source": [
    "for stock in tickers_to_use:\n",
    "    stock_predictions = y_pred[:,tickers_to_use.index(stock)]\n",
    "    stock_predictions = pd.Series(stock_predictions)\n",
    "    stock_values = testing_data[stock][stock]\n",
    "\n",
    "    other_signals_1 = generate_signals(stock_predictions.values, stock_predictions.values, pct_within)\n",
    "    other_signals_2 = generate_signals(stock_predictions.values, stock_values.values, pct_within)\n",
    "    returns = other_signals_1 * testing_data[stock]['Returns']\n",
    "    print(stock, np.exp(returns.sum()))\n",
    "    returns = other_signals_2 * testing_data[stock]['Returns']\n",
    "    print(stock, np.exp(returns.sum()))\n",
    "    print(stock, np.exp(testing_data[stock]['Returns'].sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns after tweaking the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step \n",
      "[[0.5384269 ]\n",
      " [0.538408  ]\n",
      " [0.53938955]\n",
      " [0.53859395]\n",
      " [0.53777885]\n",
      " [0.5372849 ]\n",
      " [0.537275  ]\n",
      " [0.53642476]\n",
      " [0.5360746 ]\n",
      " [0.53168404]]\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "[[0.4253182 ]\n",
      " [0.42593852]\n",
      " [0.42814544]\n",
      " [0.4289689 ]\n",
      " [0.43288654]\n",
      " [0.43713403]\n",
      " [0.44528708]\n",
      " [0.4596296 ]\n",
      " [0.464339  ]\n",
      " [0.4620208 ]]\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "[[0.49002996]\n",
      " [0.4897161 ]\n",
      " [0.4894244 ]\n",
      " [0.48188424]\n",
      " [0.47182366]\n",
      " [0.45035017]\n",
      " [0.4476017 ]\n",
      " [0.44435114]\n",
      " [0.44333696]\n",
      " [0.44008464]]\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "[[0.42886913]\n",
      " [0.42654267]\n",
      " [0.42421773]\n",
      " [0.422743  ]\n",
      " [0.42392358]\n",
      " [0.42451742]\n",
      " [0.425376  ]\n",
      " [0.428599  ]\n",
      " [0.4296613 ]\n",
      " [0.42515194]]\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "[[0.43925112]\n",
      " [0.44066843]\n",
      " [0.44974995]\n",
      " [0.4539132 ]\n",
      " [0.464751  ]\n",
      " [0.46920094]\n",
      " [0.47042862]\n",
      " [0.47284803]\n",
      " [0.4761449 ]\n",
      " [0.4798452 ]]\n",
      "AAPL.O 25 60 5 0.000505050505050505 1.5681761353413428 1.580515710382514\n",
      "MSFT.O 25 60 5 0.0 1.5423978202722686 1.7140622284025726\n",
      "INTC.O 25 60 5 0.002929292929292929 2.2834777826103694 1.3998873556744589\n",
      "AMZN.O 25 60 5 0.005858585858585858 1.3420367584674364 2.078782912839833\n",
      "GS.N 25 60 5 0.0 1.3114617610556611 1.2639390292819888\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "    \n",
    "if single_model_for_all_tickers:\n",
    "    y_pred = model.predict(X_test)\n",
    "else:\n",
    "    y_pred = np.zeros((len(X_test), n_tickers))\n",
    "    i = 0\n",
    "    for ticker in tickers_to_use:\n",
    "        X_test, Y_test = test_data[ticker]\n",
    "        y_pred_temp = models[ticker].predict(X_test)\n",
    "        print(y_pred_temp[:10])\n",
    "        if classification:\n",
    "            if y_pred_temp.ndim == 3:\n",
    "                y_pred_temp = np.argmax(y_pred_temp, axis = 2)\n",
    "            elif y_pred_temp.ndim == 2:\n",
    "                y_pred_temp = np.argmax(y_pred_temp, axis = 1)\n",
    "            y_pred_temp = np.where(y_pred_temp == 0, -1, y_pred_temp)\n",
    "        if y_pred_temp.ndim == 2:\n",
    "            y_pred_temp = y_pred_temp.flatten()\n",
    "        y_pred[:,i] = y_pred_temp\n",
    "        i += 1\n",
    "testing_data = {}\n",
    "entire_data = {}\n",
    "training_data = {}\n",
    "for stock in tickers_to_use:\n",
    "    entire_data[stock] = data[stock]\n",
    "    testing_data[stock] = pd.DataFrame(test_data[stock][1].flatten(), columns = [stock])\n",
    "    testing_data[stock]['unscaled'] = pd.DataFrame(data[stock].iloc[-len(y_pred):]).values\n",
    "    testing_data[stock]['Returns'] = np.log(testing_data[stock]['unscaled'] / testing_data[stock]['unscaled'].shift(1))\n",
    "\n",
    "for stock in tickers_to_use:\n",
    "    stock_predictions = y_pred[:,tickers_to_use.index(stock)]\n",
    "    stock_predictions = pd.Series(stock_predictions)\n",
    "    stock_values = testing_data[stock][stock]\n",
    "    max_return = -np.inf\n",
    "    best_low = None\n",
    "    best_high = None\n",
    "    best_window = None\n",
    "    best_pct_within = None\n",
    "    for window in range(5, 30, 2):\n",
    "        stock_rsi = calculate_rsi(stock_predictions, window)\n",
    "        macd_line, signal_line, histogram = calculate_macd(stock_predictions)\n",
    "        stock_macd = macd_line - signal_line\n",
    "        for low in range(25, 40, 2):\n",
    "            for high in range(60, 65, 1):\n",
    "                for pct_within in np.linspace(0.0, 0.01, 100):\n",
    "                    rsi_signals = rsi_trading_strategy(stock_rsi, low, high)\n",
    "                    rsi_signals = np.where(rsi_signals > 0, 1, -1)\n",
    "                    macd_signals = macd_trading_strategy(macd_line, signal_line)\n",
    "                    macd_signals = np.where(macd_signals > 0, 1, -1)\n",
    "                    other_signals_1 = generate_signals(stock_predictions.values, stock_predictions.values, pct_within)\n",
    "                    other_signals_2 = generate_signals(stock_predictions.values, stock_values.values, pct_within)\n",
    "\n",
    "                    # Use the majority vote to determine the final signal\n",
    "                    signals = rsi_signals + macd_signals + other_signals_1\n",
    "                    signals = np.where(signals > 0, 1, -1)\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "                        best_window = window\n",
    "                        best_pct_within = pct_within\n",
    "                    \n",
    "                    # Use the majority vote to determine the final signal\n",
    "                    signals = rsi_signals + macd_signals + other_signals_2\n",
    "                    signals = np.where(signals > 0, 1, -1)\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "                        best_window = window\n",
    "                        best_pct_within = pct_within\n",
    "                    \n",
    "                    signals = np.where((stock_rsi < low) & (stock_macd > 0), 1,\n",
    "                                np.where((stock_rsi > high) & (stock_macd < 0), -1, 0))\n",
    "                    for i in range(1, len(testing_data)):\n",
    "                        if signals[i] == 0:\n",
    "                            signals[i] = signals[i - 1]\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "                        best_window = window\n",
    "                        best_pct_within = pct_within\n",
    "\n",
    "                    signals = np.where((stock_rsi < low) & (stock_macd > 0), 1,\n",
    "                                np.where((stock_rsi > high) & (stock_macd < 0), -1, 0))\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "                        best_window = window\n",
    "                        best_pct_within = pct_within\n",
    "                    \n",
    "                    # Only other_signals_1\n",
    "                    signals = other_signals_1\n",
    "                    signals = np.where(signals > 0, 1, -1)\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "                        best_window = window\n",
    "                        best_pct_within = pct_within\n",
    "                    # Only rsi_signals\n",
    "                    signals = rsi_signals\n",
    "                    signals = np.where(signals > 0, 1, -1)\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "                    # Only macd_signals\n",
    "                    signals = macd_signals\n",
    "                    signals = np.where(signals > 0, 1, -1)\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "                    # Only other_signals_2\n",
    "                    signals = other_signals_2\n",
    "                    signals = np.where(signals > 0, 1, -1)\n",
    "                    returns = signals * testing_data[stock]['Returns']\n",
    "                    if np.exp(returns.sum()) > max_return:\n",
    "                        max_return = np.exp(returns.sum())\n",
    "                        best_low = low\n",
    "                        best_high = high\n",
    "    print(stock, best_low, best_high, best_window, best_pct_within, max_return, np.exp(testing_data[stock]['Returns'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
